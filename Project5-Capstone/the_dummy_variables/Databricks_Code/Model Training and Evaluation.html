<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Model Training and Evaluation - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/img/favicon.ico"/>
<script>window.settings = {"enableSshKeyUI":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/latest.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableClearStateFeature":false,"dbcForumURL":"http://forums.databricks.com/","maxCustomTags":45,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"spark_heap_memory":21145,"instance_type_id":"r3.xlarge","node_type_id":"r3.xlarge","description":"r3.xlarge (beta)","support_cluster_tags":true,"container_memory_mb":26432,"memory_mb":31232,"category":"Memory Optimized","num_cores":4.0,"support_ebs_volumes":true},{"spark_heap_memory":46131,"instance_type_id":"r3.2xlarge","node_type_id":"r3.2xlarge","description":"r3.2xlarge (beta)","support_cluster_tags":true,"container_memory_mb":57664,"memory_mb":62464,"category":"Memory Optimized","num_cores":8.0,"support_ebs_volumes":true},{"spark_heap_memory":96102,"instance_type_id":"r3.4xlarge","node_type_id":"r3.4xlarge","description":"r3.4xlarge (beta)","support_cluster_tags":true,"container_memory_mb":120128,"memory_mb":124928,"category":"Memory Optimized","num_cores":16.0,"support_ebs_volumes":true},{"spark_heap_memory":196044,"instance_type_id":"r3.8xlarge","node_type_id":"r3.8xlarge","description":"r3.8xlarge (beta)","support_cluster_tags":true,"container_memory_mb":245056,"memory_mb":249856,"category":"Memory Optimized","num_cores":32.0,"support_ebs_volumes":true},{"spark_heap_memory":8448,"instance_type_id":"c3.2xlarge","node_type_id":"c3.2xlarge","description":"c3.2xlarge (beta)","support_cluster_tags":true,"container_memory_mb":10560,"memory_mb":15360,"category":"Compute Optimized","num_cores":8.0,"support_ebs_volumes":true},{"spark_heap_memory":20736,"instance_type_id":"c3.4xlarge","node_type_id":"c3.4xlarge","description":"c3.4xlarge (beta)","support_cluster_tags":true,"container_memory_mb":25920,"memory_mb":30720,"category":"Compute Optimized","num_cores":16.0,"support_ebs_volumes":true},{"spark_heap_memory":45312,"instance_type_id":"c3.8xlarge","node_type_id":"c3.8xlarge","description":"c3.8xlarge (beta)","support_cluster_tags":true,"container_memory_mb":56640,"memory_mb":61440,"category":"Compute Optimized","num_cores":32.0,"support_ebs_volumes":true},{"spark_heap_memory":21145,"instance_type_id":"i2.xlarge","node_type_id":"i2.xlarge","description":"i2.xlarge (beta)","support_cluster_tags":true,"container_memory_mb":26432,"memory_mb":31232,"category":"Storage Optimized","num_cores":4.0,"support_ebs_volumes":true},{"spark_heap_memory":46131,"instance_type_id":"i2.2xlarge","node_type_id":"i2.2xlarge","description":"i2.2xlarge (beta)","support_cluster_tags":true,"container_memory_mb":57664,"memory_mb":62464,"category":"Storage Optimized","num_cores":8.0,"support_ebs_volumes":true},{"spark_heap_memory":96102,"instance_type_id":"i2.4xlarge","node_type_id":"i2.4xlarge","description":"i2.4xlarge (beta)","support_cluster_tags":true,"container_memory_mb":120128,"memory_mb":124928,"category":"Storage Optimized","num_cores":16.0,"support_ebs_volumes":true},{"spark_heap_memory":196044,"instance_type_id":"i2.8xlarge","node_type_id":"i2.8xlarge","description":"i2.8xlarge (beta)","support_cluster_tags":true,"container_memory_mb":245056,"memory_mb":249856,"category":"Storage Optimized","num_cores":32.0,"support_ebs_volumes":true},{"spark_heap_memory":23800,"instance_type_id":"r3.2xlarge","node_type_id":"memory-optimized","description":"Memory Optimized","support_cluster_tags":false,"container_memory_mb":28000,"memory_mb":30720,"category":"Memory Optimized","num_cores":4.0,"support_ebs_volumes":false},{"spark_heap_memory":9702,"instance_type_id":"c3.4xlarge","node_type_id":"compute-optimized","description":"Compute Optimized","support_cluster_tags":false,"container_memory_mb":12128,"memory_mb":15360,"category":"Compute Optimized","num_cores":8.0,"support_ebs_volumes":false}],"default_node_type_id":"memory-optimized"},"enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":0,"enableTableHandler":true,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"enableLargeResultDownload":true,"zoneInfos":[{"id":"us-east-1e","isDefault":true},{"id":"us-east-1b","isDefault":false},{"id":"us-east-1c","isDefault":false},{"id":"us-east-1d","isDefault":false}],"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":false,"enableMaxConcurrentRuns":false,"enableJobAclsConfig":true,"enableFullTextSearch":true,"enableElasticSparkUI":true,"enableNewClustersCreate":false,"clusters":true,"allowRunOnPendingClusters":true,"applications":false,"fileStoreBase":"FileStore","enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":false,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":true,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"sparkVersions":[{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0 RC3 (Scala 2.11)","packageLabel":"spark-image-c62951889ee5761774cdfbfb8f237f3b880af034e1b31ff0656af0c21698a3bf","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-6c2dd678fff350c03ba0e945bab52d0080cd857a39c99a22131b3e824bb8096f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":true},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-4f22a8d3016bc3dce9e839b10418815a7d28afff3a027b43bd2b041c42b2a89d","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-596490ba3e0ca4b62abb048923fc70de84e319cf527bb7a5a8f609bbf780bed8","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":true},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0 RC3 (Scala 2.10)","packageLabel":"spark-image-a7e1c0956b4ff2607522aa78845043f8c18c4a4354c5403da870718bb26e23dc","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":false,"customerVisible":true}],"enableRestrictedClusterCreation":false,"enableFeedback":true,"enableClusterAutoScaling":true,"enableUserVisibleDefaultTags":false,"defaultNumWorkers":8,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":true,"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"class-node":1,"p2.8xlarge":16,"r3.8xlarge":8,"dev-tier-node":1,"c3.8xlarge":4,"r3.4xlarge":4,"i2.4xlarge":6,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"memory-optimized":1,"p2.16xlarge":24,"c3.2xlarge":1,"c4.2xlarge":1,"i2.xlarge":1.5,"compute-optimized":1,"c4.4xlarge":2,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"c4.8xlarge":4,"r3.xlarge":1,"i2.8xlarge":12},"enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":false,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.33.220","accountsLimit":-1,"enableX509Authentication":false,"enableNotebookGitBranching":true,"local":false,"enableClusterAutoScalingForJobs":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":30,"disableS3TableImport":false,"deploymentMode":"production","useSpotForWorkers":true,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"enableCssTransitions":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":true,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableNotebookGitVersioning":true,"files":"files/","feedbackEmail":"support@databricks.com","enableDriverLogsUI":true,"disableLegacyDashboards":false,"enableWorkspaceAclsConfig":true,"dropzoneMaxFileSize":4096,"enableNewClustersList":false,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"defaultSparkVersion":{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-4f22a8d3016bc3dce9e839b10418815a7d28afff3a027b43bd2b041c42b2a89d","upgradable":true,"deprecated":false,"customerVisible":true},"enableCustomSpotPricing":true,"enableMountAclsConfig":false,"useDevTierHomePage":false,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","showSqlEndpoints":true,"enableClusterAclsByTier":true,"databricksDocsBaseUrl":"https://docs.databricks.com/","disallowAddingAdmins":false,"enableSparkConfUI":true,"featureTier":"UNKNOWN_TIER","enableOrgSwitcherUI":false,"clustersLimit":-1,"enableJdbcImport":true,"logfiles":"logfiles/","enableWebappSharding":false,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"http://feedback.databricks.com/forums/263785-product-feedback","enableMountAclService":true,"enableWorkspaceAcls":true,"maxClusterTagKeyLength":127,"gitHash":"8719902676c4e1cefbc31755c1726979bdf286d0","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":false,"enableDebugUI":false,"allowNonAdminUsers":true,"enableSingleSignOnByTier":true,"enableJobsRetryOnTimeout":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/","enableSparkPackages":true,"dynamicSparkVersions":true,"enableNotebookHistoryUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":true,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"upgradeURL":"","notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":true,"enableTerminal":false,"defaultMemoryPerContainerMB":28000,"enablePresenceUI":true,"accounts":true,"useFramedStaticNotebooks":false,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4,"enableNewClustersGet":false,"showSqlProxyUI":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":1253,"name":"Model Training and Evaluation","language":"python","commands":[{"version":"CommandV1","origId":1255,"guid":"85edb0b5-cf4c-4520-8f36-6ce5a50444b9","subtype":"command","commandType":"auto","position":0.25,"command":"%md # Import Data","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5e83a8ec-a258-49a9-bcf3-5c9a0e4f64b9"},{"version":"CommandV1","origId":1256,"guid":"42dcb291-7d5a-40fa-afcb-92ae9b410f72","subtype":"command","commandType":"auto","position":0.5,"command":"# Run this cell to setup data path\nimport os\nfrom pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n\n# Configuration\ndatapath = os.getcwd()\nif datapath.find('databricks') != -1:\n  ACCESS_KEY =   \"\"\n  SECRET_KEY = \"+\"\n  ENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\n  AWS_BUCKET_NAME = \"dummyvarsmillionsong\"\n  MOUNT_NAME = \"/S3/\"\n  datapath = \"s3a://%s:%s@%s/\" %(ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME)\nelse:\n  print \"Error! Not on databricks server\"\n\n# Load and parse ratings\ntripletsRDD = sc.textFile('processed_data/ratings_full.txt')\nratings_full = tripletsRDD.map(lambda l: l.split(','))\\\n    .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n\n# Sanity check\nprint \"number of ratings\", ratings_full.count()\n\n# Get products and users\nproducts = ratings_full.map(lambda x: x.product).distinct()\nusers = ratings_full.map(lambda x: x.user).distinct().collect()\n\nratings_full.cache()\nproducts.cache()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">number of ratings 48373586\n<span class=\"ansired\">Out[</span><span class=\"ansired\">2</span><span class=\"ansired\">]: </span>PythonRDD[2455] at RDD at PythonRDD.scala:44\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Cancelled","error":null,"workflows":[],"startTime":1.482025750688E12,"submitTime":1.482025749308E12,"finishTime":1.482025842606E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8c1d54d2-2f09-4e7f-a1d4-3670d3515fe6"},{"version":"CommandV1","origId":1257,"guid":"1d4317b0-f3a0-40e7-b8bc-c36b82e2469a","subtype":"command","commandType":"auto","position":0.75,"command":"%md # Helper Functions","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4efa4823-b80a-43b7-9cd4-97df22e0dcf4"},{"version":"CommandV1","origId":1258,"guid":"e11ae712-61a3-40da-946a-9b860181dcac","subtype":"command","commandType":"auto","position":1.0,"command":"\"\"\"Helper functions for performing parameter tuning and cross-validation\"\"\"\nfrom operator import add\nfrom __future__ import division\nfrom sklearn.cross_validation import KFold\n\nimport csv, os\nimport datetime\nfrom itertools import product\nfrom functools import partial\nfrom multiprocessing.pool import ThreadPool\nfrom numpy import mean, std, random\n\n\ndef evaluate_model(model, ratings, kfolds, params, fold_i):\n  \"\"\"Perform cross-validation on ith fold\"\"\"\n\n  # Get training test split of users\n  train_indices, test_indices = kfolds[fold_i]\n  train_users = sc.parallelize([users[i] for i in train_indices])\n  test_users = sc.parallelize([users[i] for i in test_indices])\n\n  # Aggregate ratings by user\n  ratings_by_user = ratings.map(lambda x: (x[0], (x[1], x[2]))).groupByKey().map(lambda x : (x[0], list(x[1])))\n\n  # Get train and test ratings\n  train_by_users = ratings_by_user.join(train_users.map(lambda x: (x, 0))).map(lambda x: (x[0], x[1][0]))\n  train = train_by_users\\\n    .flatMapValues(lambda x: x).map(lambda x: Rating(x[0], x[1][0], x[1][1]))\n  test_by_users = ratings_by_user.join(test_users.map(lambda x: (x, 0))).map(lambda x: (x[0], x[1][0]))\n\n  # Randomly remove half of test user's items\n  def split(items):\n    first, second = list(KFold(len(items), n_folds = 2, shuffle = True))[0]\n    leave_in = [items[i] for i in first]\n    leave_out = [items[i] for i in second]\n    return (leave_in, leave_out)\n\n  test_by_users_split = test_by_users\\\n    .map(lambda x: (x[0], split(x[1])))\n\n  test_visible_by_users = test_by_users_split\\\n    .map(lambda x: (x[0], x[1][0]))\n\n  test_visible = test_visible_by_users\\\n    .flatMapValues(lambda x: x).map(lambda x: Rating(x[0], x[1][0], x[1][1]))\n\n  test_hidden_by_users = test_by_users_split\\\n    .map(lambda x: (x[0], [pair[0] for pair in x[1][1]]))\n\n  # Join training and visible test data\n  train_and_test_visible = train.union(test_visible)\n\n  # Train the model\n  model.train_model(train_and_test_visible, params)\n\n  # HACK :Get a subset of test users to get recommendations\n  num_users = 100\n  test_users_subset = test_users.takeSample(False, num_users, seed=100)\n\n  predictions_by_user = model.get_predictions(test_users_subset, products)\n\n  # Remove songs already in user history\n  product_history_by_user = test_by_users_split\\\n    .map(lambda x: (x[0], [pair[0] for pair in x[1][0]]))\n  predictions_and_history = predictions_by_user.join(product_history_by_user)\n  predictions = predictions_and_history.map(lambda x: (x[0], [s for s in x[1][0] if s not in x[1][1]]))\n\n  # Join predictions and hidden by user keys\n  predictions_and_labels = predictions_by_user.join(test_hidden_by_users).map(lambda x: x[1])\n\n  # Get mAP\n  from pyspark.mllib.evaluation import RankingMetrics\n  metrics = RankingMetrics(predictions_and_labels)\n  mAP = metrics.meanAveragePrecision\n  return (fold_i, mAP)\n\n\ndef perform_cross_validation(model, ratings, n_folds, threaded, params):\n  \"\"\"Perform cross validation on given parameters\"\"\"\n  kf = list(KFold(len(users), n_folds=n_folds, shuffle = True))\n  \n  print \"Running {} fold cv with params:\".format(n_folds)\n  print params\n  \n  mAP_scores = []\n  if threaded:\n    tpool = ThreadPool(processes=n_folds)\n    mAP_scores = tpool.map(partial(evaluate_model, model, ratings, kf, params), range(n_folds))\n  else:\n    for i in range(n_folds):\n      mAP_scores.append(evaluate_model(model, ratings, kf, params, i))\n  mAP_mean = mean([x[1] for x in mAP_scores])\n  mAP_std = std([x[1] for x in mAP_scores])\n  params['mAP_mean'] = mAP_mean\n  params['mAP_std'] = mAP_std\n  return params\n\ndef grid_search_cv(model, ratings, param_grid, n_folds = 5, threaded=True):\n  \"\"\"Perform a grid search given the parameter grid\"\"\"\n  \n  params_list = []\n  for vals in product(*param_grid.values()):\n    params = dict(zip(param_grid.keys(), vals))\n    params_list.append(params)\n    \n  results = []\n  if threaded:\n    tpool = ThreadPool(processes=len(params_list))\n    results = tpool.map(partial(perform_cross_validation, model, ratings, n_folds, threaded), params_list)\n  else:\n    for params in params_list:\n      results.append(perform_cross_validation(model, ratings, n_folds, threaded, params))\n      \n  return results\n\ndef output_results(model_results, file_name=''):\n  \"\"\"Output model results to file\"\"\"\n  \n  print \"model results:\", model_results\n\n  # Get best parameters of model\n  best_results = sorted(model_results, key=lambda x: x['mAP_mean'], reverse=True)[0]\n  print \"best results:\", best_results\n\n  if file_name:\n    print \"Saving results to file...\"\n    # Output CV results to time stamped csv file\n    time_stamp = '{:%Y_%m_%d_%H_%M_%S_}'.format(datetime.datetime.now())\n    file_name = time_stamp + file_name\n    path_to_results = '/mnt/S3/results'\n\n    # Convert model results in a dataframe\n    keys = model_results[0].keys() # header\n    df = sc.parallelize([[float(params[key]) for key in keys] for params in model_results]).toDF(keys)\n    df.repartition(1).write.option(\"header\", \"true\").csv(os.path.join(path_to_results, file_name))\n    \nclass als_recommender():\n  \"\"\"Class to represent recommendation models\"\"\"\n  \n  def __init__(self):\n    \"\"\"Create the Alternating Least Squares model from pyspark's mllib\"\"\"\n    self.name = 'ALS'\n  \n  def train_model(self, data, params):\n    \"\"\"Train on the data\"\"\"\n    self.model = ALS.train(data, **params)\n    \n  def get_predictions(self, users, products):\n    \"\"\"Get predictions for users\"\"\"\n    # Create the cartesian product of products and users to predict\n    user_product_pairs = sc.parallelize(users).cartesian(products)\n\n    # Choose top recommendations\n    predictions = self.model.predictAll(user_product_pairs)\n    predictions_keys = predictions.map(lambda x: (x[0], (x[1], x[2])))\n    predictions_by_user = predictions_keys.groupByKey().map(lambda x : (x[0], [z[0] for z in sorted(list(x[1]), key=lambda y: y[1], reverse=True)]))\n    return predictions_by_user\n  \n  def save(self, output_path):\n    \"\"\"Save model to file\"\"\"\n    print \"Saving model to file...\"\n    self.model.save(sc, output_path)\n    \nclass implicit_recommender(als_recommender):\n  \"\"\"Implicit version of the ALS method\"\"\"\n  \n  def __init__(self):\n    \"\"\"Create the Alternating Least Squares model from pyspark's mllib\"\"\"\n    self.name = 'ALS_Implicit'\n    \n  def train_model(self, data, params):\n    \"\"\"Train on the data\"\"\"\n    self.model = ALS.trainImplicit(data, **params)\n    \nclass popularity_recommender():\n  \"\"\"Choose the most popular songs as recommendations\"\"\"\n  \n  def __init__(self):\n    \"\"\"Create popularity model\"\"\"\n    self.name = 'Popularity'\n  \n  def train_model(self, data, params):\n    # Get songs by popularity\n    self.num_songs = params['num_songs']\n  \n  def get_predictions(self, users, products):\n    \"\"\"Get predictions for users\"\"\"\n    \n    num_songs = self.num_songs\n    songs_by_popularity = ratings\\\n      .map(lambda x: (x[1], 1))\\\n      .reduceByKey(lambda a, b: a + b)\\\n      .sortBy(lambda x: x[1], ascending=False)\\\n      .map(lambda x: x[0])\\\n      .take(num_songs) # take top n popular\n      \n    # Create recommendations for each user\n    predictions_by_user = sc.parallelize(users).map(lambda x: (x, songs_by_popularity))\n    return predictions_by_user","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> invalid syntax","error":"<div class=\"ansiout\"><span class=\"ansicyan\">  File </span><span class=\"ansigreen\">&quot;&lt;ipython-input-3-699f1a636e13&gt;&quot;</span><span class=\"ansicyan\">, line </span><span class=\"ansigreen\">150</span>\n<span class=\"ansiyellow\">    predictions = se lf.model.predictAll(user_product_pairs)</span>\n<span class=\"ansigrey\">                      ^</span>\n<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> invalid syntax\n\n</div>","workflows":[],"startTime":1.482025842611E12,"submitTime":1.482025750473E12,"finishTime":1.482025843284E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6084049f-0e79-47cf-8a2d-ca624cfc6f5c"},{"version":"CommandV1","origId":1259,"guid":"acefce26-fc12-4835-ad61-7089c375d7fa","subtype":"command","commandType":"auto","position":2.0,"command":"%md # Parameter Tuning and Cross-Validation","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"96bd50a1-85f3-45d1-81d1-5de9f6ec7f4c"},{"version":"CommandV1","origId":1260,"guid":"58fc4b3b-ce3a-4d2b-9300-e4db9906c713","subtype":"command","commandType":"auto","position":2.5,"command":"# Perform cross-validation\nparams = {'rank': 50, \n              'iterations': 5,\n              'alpha': 40.,\n              'lambda_': 1.0\n} \nmodel = implicit_recommender()\nperform_cross_validation(model, ratings, 2, threaded=True, params=params)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Running 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;rank&apos;: 50}\n<span class=\"ansired\">Out[</span><span class=\"ansired\">67</span><span class=\"ansired\">]: </span>\n{&apos;alpha&apos;: 40.0,\n &apos;iterations&apos;: 5,\n &apos;lambda_&apos;: 1.0,\n &apos;mAP_mean&apos;: 0.23413775924921898,\n &apos;mAP_std&apos;: 0.076556334200525822,\n &apos;rank&apos;: 50}\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">AttributeError</span>: implicit_recommender instance has no attribute &apos;map&apos;","error":"<div class=\"ansiout\">Running 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;rank&apos;: 50}\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-65-cb901ed1626f&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      6</span> } \n<span class=\"ansigreen\">      7</span> model <span class=\"ansiyellow\">=</span> implicit_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 8</span><span class=\"ansiyellow\"> </span>perform_cross_validation<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">2</span><span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">=</span>True<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">=</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-64-4a2a0c50ed17&gt;</span> in <span class=\"ansicyan\">perform_cross_validation</span><span class=\"ansiblue\">(model, ratings, n_folds, threaded, params)</span>\n<span class=\"ansigreen\">    101</span>   <span class=\"ansigreen\">if</span> threaded<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    102</span>     tpool <span class=\"ansiyellow\">=</span> ThreadPool<span class=\"ansiyellow\">(</span>processes<span class=\"ansiyellow\">=</span>n_folds<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 103</span><span class=\"ansiyellow\">     </span>mAP_scores <span class=\"ansiyellow\">=</span> tpool<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>partial<span class=\"ansiyellow\">(</span>evaluate_model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> model<span class=\"ansiyellow\">,</span> kf<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> range<span class=\"ansiyellow\">(</span>n_folds<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    104</span>   <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    105</span>     <span class=\"ansigreen\">for</span> i <span class=\"ansigreen\">in</span> range<span class=\"ansiyellow\">(</span>n_folds<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">map</span><span class=\"ansiblue\">(self, func, iterable, chunksize)</span>\n<span class=\"ansigreen\">    249</span>         &apos;&apos;&apos;\n<span class=\"ansigreen\">    250</span>         <span class=\"ansigreen\">assert</span> self<span class=\"ansiyellow\">.</span>_state <span class=\"ansiyellow\">==</span> RUN<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 251</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>map_async<span class=\"ansiyellow\">(</span>func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>get<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    252</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    253</span>     <span class=\"ansigreen\">def</span> imap<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">get</span><span class=\"ansiblue\">(self, timeout)</span>\n<span class=\"ansigreen\">    565</span>             <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    566</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 567</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    568</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    569</span>     <span class=\"ansigreen\">def</span> _set<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> i<span class=\"ansiyellow\">,</span> obj<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: implicit_recommender instance has no attribute &apos;map&apos;\n</div>","workflows":[],"startTime":1.481676337401E12,"submitTime":1.481676343722E12,"finishTime":1.481676362467E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b7e6d58a-ece4-4b73-a4f0-282c8040c58d"},{"version":"CommandV1","origId":1261,"guid":"b60df6a2-8837-4239-b23d-76fd2d132d37","subtype":"command","commandType":"auto","position":3.0,"command":"# Perform parameter tuning using grid search\nparam_grid = {'rank': [1], \n              'iterations': [1],\n              'alpha': [40., 100., 200.],\n              'lambda_': [1.0]\n}\n\n# Run grid search\nmodel = implicit_recommender()\nmodel_results = grid_search_cv(model, ratings, param_grid, n_folds = 2)\noutput_results(model_results)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Running 2 fold cv with params:\n{&apos;alpha&apos;: 100.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 1, &apos;iterations&apos;: 1}\nRunning 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 1, &apos;iterations&apos;: 1}\nRunning 2 fold cv with params:\n{&apos;alpha&apos;: 200.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 1, &apos;iterations&apos;: 1}\nmodel results: [{&apos;mAP_mean&apos;: 0.0017639137127555555, &apos;rank&apos;: 1, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 1, &apos;mAP_std&apos;: 0.00061816318798917449, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.0015715130016900648, &apos;rank&apos;: 1, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 1, &apos;mAP_std&apos;: 0.00014078537365392284, &apos;alpha&apos;: 100.0}, {&apos;mAP_mean&apos;: 0.0023452752236270704, &apos;rank&apos;: 1, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 1, &apos;mAP_std&apos;: 0.0002943392553641979, &apos;alpha&apos;: 200.0}]\nbest results: {&apos;mAP_mean&apos;: 0.0023452752236270704, &apos;rank&apos;: 1, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 1, &apos;mAP_std&apos;: 0.0002943392553641979, &apos;alpha&apos;: 200.0}\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">AttributeError</span>: implicit_recommender instance has no attribute &apos;map&apos;","error":"<div class=\"ansiout\">Running 2 fold cv with params:\n{&apos;alpha&apos;: 100.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 1, &apos;iterations&apos;: 1}\nRunning 2 fold cv with params:\n{&apos;alpha&apos;: 200.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 1, &apos;iterations&apos;: 1}\nRunning 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 1, &apos;iterations&apos;: 1}\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-68-bbf4f8f5e60b&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      8</span> <span class=\"ansired\"># Run grid search</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      9</span> model <span class=\"ansiyellow\">=</span> implicit_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 10</span><span class=\"ansiyellow\"> </span>model_results <span class=\"ansiyellow\">=</span> grid_search_cv<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> param_grid<span class=\"ansiyellow\">,</span> n_folds <span class=\"ansiyellow\">=</span> <span class=\"ansicyan\">2</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     11</span> <span class=\"ansigreen\">print</span> <span class=\"ansiblue\">&quot;model results:&quot;</span><span class=\"ansiyellow\">,</span> model_results<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     12</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-66-df432a929d37&gt;</span> in <span class=\"ansicyan\">grid_search_cv</span><span class=\"ansiblue\">(model, ratings, param_grid, n_folds, threaded)</span>\n<span class=\"ansigreen\">    122</span>   <span class=\"ansigreen\">if</span> threaded<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    123</span>     tpool <span class=\"ansiyellow\">=</span> ThreadPool<span class=\"ansiyellow\">(</span>processes<span class=\"ansiyellow\">=</span>len<span class=\"ansiyellow\">(</span>params_list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 124</span><span class=\"ansiyellow\">     </span>results <span class=\"ansiyellow\">=</span> tpool<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>partial<span class=\"ansiyellow\">(</span>perform_cross_validation<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> model<span class=\"ansiyellow\">,</span> n_folds<span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> params_list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    125</span>   <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    126</span>     <span class=\"ansigreen\">for</span> params <span class=\"ansigreen\">in</span> params_list<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">map</span><span class=\"ansiblue\">(self, func, iterable, chunksize)</span>\n<span class=\"ansigreen\">    249</span>         &apos;&apos;&apos;\n<span class=\"ansigreen\">    250</span>         <span class=\"ansigreen\">assert</span> self<span class=\"ansiyellow\">.</span>_state <span class=\"ansiyellow\">==</span> RUN<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 251</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>map_async<span class=\"ansiyellow\">(</span>func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>get<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    252</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    253</span>     <span class=\"ansigreen\">def</span> imap<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">get</span><span class=\"ansiblue\">(self, timeout)</span>\n<span class=\"ansigreen\">    565</span>             <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    566</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 567</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    568</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    569</span>     <span class=\"ansigreen\">def</span> _set<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> i<span class=\"ansiyellow\">,</span> obj<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: implicit_recommender instance has no attribute &apos;map&apos;\n</div>","workflows":[],"startTime":1.481741548539E12,"submitTime":1.481741547479E12,"finishTime":1.481741600946E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f3d4904b-f5ee-4de4-a48b-d442e69aa9e3"},{"version":"CommandV1","origId":1262,"guid":"937a9c77-3196-40cb-a095-abc2d9642675","subtype":"command","commandType":"auto","position":3.25,"command":"%md # Save Model Results","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"087de8a4-6246-47c5-a706-bc3bd60f76e1"},{"version":"CommandV1","origId":1263,"guid":"cb2f5ff6-620e-4934-b27f-5c717134ba73","subtype":"command","commandType":"auto","position":3.5,"command":"# Output the results to file\nimport datetime\n\n# Output CV results\noutput_results(model_results, 'test_123')","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">model results: [{&apos;mAP_mean&apos;: 0.0017639137127555555, &apos;rank&apos;: 1, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 1, &apos;mAP_std&apos;: 0.00061816318798917449, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.0015715130016900648, &apos;rank&apos;: 1, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 1, &apos;mAP_std&apos;: 0.00014078537365392284, &apos;alpha&apos;: 100.0}, {&apos;mAP_mean&apos;: 0.0023452752236270704, &apos;rank&apos;: 1, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 1, &apos;mAP_std&apos;: 0.0002943392553641979, &apos;alpha&apos;: 200.0}]\nbest results: {&apos;mAP_mean&apos;: 0.0023452752236270704, &apos;rank&apos;: 1, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 1, &apos;mAP_std&apos;: 0.0002943392553641979, &apos;alpha&apos;: 200.0}\nSaving results to file...\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">AttributeError</span>: &apos;ALS&apos; object has no attribute &apos;save&apos;","error":"<div class=\"ansiout\">Saving model to file...\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-56-816b8bcfd3f1&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     11</span> <span class=\"ansired\"># Output the model</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     12</span> path_to_models <span class=\"ansiyellow\">=</span> <span class=\"ansiblue\">&apos;/mnt/S3/models&apos;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 13</span><span class=\"ansiyellow\"> </span>model<span class=\"ansiyellow\">.</span>save<span class=\"ansiyellow\">(</span>os<span class=\"ansiyellow\">.</span>path<span class=\"ansiyellow\">.</span>join<span class=\"ansiyellow\">(</span>path_to_models<span class=\"ansiyellow\">,</span> file_name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-43-4899feb3557c&gt;</span> in <span class=\"ansicyan\">save</span><span class=\"ansiblue\">(self, output_path)</span>\n<span class=\"ansigreen\">    163</span>     <span class=\"ansiblue\">&quot;&quot;&quot;Save model to file&quot;&quot;&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    164</span>     <span class=\"ansigreen\">print</span> <span class=\"ansiblue\">&quot;Saving model to file...&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 165</span><span class=\"ansiyellow\">     </span>self<span class=\"ansiyellow\">.</span>model<span class=\"ansiyellow\">.</span>save<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">,</span> os<span class=\"ansiyellow\">.</span>path<span class=\"ansiyellow\">.</span>join<span class=\"ansiyellow\">(</span>output_path<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    166</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    167</span> <span class=\"ansigreen\">class</span> implicit_recommender<span class=\"ansiyellow\">(</span>als_recommender<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;ALS&apos; object has no attribute &apos;save&apos;\n</div>","workflows":[],"startTime":1.481741748523E12,"submitTime":1.481741747449E12,"finishTime":1.48174175084E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3149b4b0-c1b8-41de-b63f-4d9da1533ad7"},{"version":"CommandV1","origId":1264,"guid":"6a0466e4-8ed8-4ef0-8bb2-9a2ba83f7baf","subtype":"command","commandType":"auto","position":3.625,"command":"# Retrain model on all data\nmodel.train_model(ratings, best_results)\n\n# Output the final model\npath_to_models = '/mnt/S3/models'\nmodel.save(os.path.join(path_to_models, file_name))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"37a78d69-3bd9-46e8-8eda-bb852408705f"},{"version":"CommandV1","origId":1265,"guid":"c64a89d4-5aa9-4e90-a5e0-e7be64d6e885","subtype":"command","commandType":"auto","position":3.75,"command":"%md # Cross-Validation Experiments","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c5a2ea03-a48f-4152-bf1a-bc6700228aaf"},{"version":"CommandV1","origId":1266,"guid":"620b897f-5781-4d98-8d7a-02cab9ebbe48","subtype":"command","commandType":"auto","position":3.875,"command":"%md ## Baseline: Popularity Model","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">ERROR: Line magic function &#96;%md&#96; not found.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"Cancelled","error":null,"workflows":[],"startTime":1.481670165871E12,"submitTime":1.481670172E12,"finishTime":1.481670165942E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2b279163-3106-4e08-a60c-c4652fadffe7"},{"version":"CommandV1","origId":1267,"guid":"9a242fb0-17d4-476d-9659-a2f424891bb6","subtype":"command","commandType":"auto","position":3.90625,"command":"# Perform cross-validation\nparams = {'num_songs': 500}\nmodel = popularity_recommender()\nperform_cross_validation(model, ratings, 5, threaded=True, params=params)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Running 5 fold cv with params:\n{&apos;num_songs&apos;: 500}\n<span class=\"ansired\">Out[</span><span class=\"ansired\">28</span><span class=\"ansired\">]: </span>\n{&apos;mAP_mean&apos;: 0.017911323770145694,\n &apos;mAP_std&apos;: 0.0036915481820646917,\n &apos;num_songs&apos;: 500}\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">TypeError</span>: perform_cross_validation() takes exactly 5 arguments (4 given)","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-89-38f5932fe35c&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      2</span> params <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">{</span><span class=\"ansiblue\">&apos;num_songs&apos;</span><span class=\"ansiyellow\">:</span> <span class=\"ansicyan\">500</span><span class=\"ansiyellow\">}</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> model <span class=\"ansiyellow\">=</span> popularity_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\"> </span>perform_cross_validation<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">2</span><span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">=</span>True<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">=</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TypeError</span>: perform_cross_validation() takes exactly 5 arguments (4 given)\n</div>","workflows":[],"startTime":1.481745595835E12,"submitTime":1.481745594633E12,"finishTime":1.481745911051E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a859a7d6-d03f-4263-af7d-029ab33f0ceb"},{"version":"CommandV1","origId":1268,"guid":"67190944-96b7-45ea-9888-c8290d141504","subtype":"command","commandType":"auto","position":3.9375,"command":"%md ## Explicit Model Performance vs. Rank","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">ERROR: Line magic function &#96;%md&#96; not found.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481670166511E12,"submitTime":1.481670172635E12,"finishTime":1.481670166532E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1e267700-9095-41dd-bad9-60e88a8d4358"},{"version":"CommandV1","origId":1269,"guid":"e482cbf0-506e-48c3-b693-6cc611acd7ed","subtype":"command","commandType":"auto","position":3.953125,"command":"# Perform parameter tuning using grid search\nparam_grid = {'rank': [10, 20, 30, 40, 50], \n              'iterations': [5],\n              'lambda_': [500.]\n}\n\n# Run grid search\nmodel = als_recommender()\nmodel_results = grid_search_cv(model, ratings, param_grid, n_folds=5, threaded=False)\noutput_results(model_results, model.name + '_vs_rank')\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Running 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 10, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 20, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 30, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 40, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nmodel results: [{&apos;mAP_mean&apos;: 0.0011717402500548732, &apos;lambda_&apos;: 500.0, &apos;rank&apos;: 10, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.00023727712483176137}, {&apos;mAP_mean&apos;: 0.00144211797716539, &apos;lambda_&apos;: 500.0, &apos;rank&apos;: 20, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.00041117179006634427}, {&apos;mAP_mean&apos;: 0.0012422760930385205, &apos;lambda_&apos;: 500.0, &apos;rank&apos;: 30, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.00021386742078030656}, {&apos;mAP_mean&apos;: 0.0012134180756659767, &apos;lambda_&apos;: 500.0, &apos;rank&apos;: 40, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.00024923990252991328}, {&apos;mAP_mean&apos;: 0.0013487014395845661, &apos;lambda_&apos;: 500.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.00031799251118286851}]\nbest results: {&apos;mAP_mean&apos;: 0.00144211797716539, &apos;lambda_&apos;: 500.0, &apos;rank&apos;: 20, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.00041117179006634427}\nSaving results to file...\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;model_restults&apos; is not defined","error":"<div class=\"ansiout\">Running 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 10, &apos;iterations&apos;: 5}\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-19-1a00df57c2f4&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      8</span> model <span class=\"ansiyellow\">=</span> als_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      9</span> model_results <span class=\"ansiyellow\">=</span> grid_search_cv<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> param_grid<span class=\"ansiyellow\">,</span> n_folds<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">5</span><span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">=</span>False<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 10</span><span class=\"ansiyellow\"> </span>output_results<span class=\"ansiyellow\">(</span>model_restults<span class=\"ansiyellow\">,</span> model<span class=\"ansiyellow\">.</span>name <span class=\"ansiyellow\">+</span> <span class=\"ansiblue\">&apos;_vs_rank&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     11</span> <span class=\"ansired\"># print &quot;model results:&quot;, model_results</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     12</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;model_restults&apos; is not defined\n</div>","workflows":[],"startTime":1.481769021189E12,"submitTime":1.481769021189E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0dc81ebb-3eeb-4115-8a2b-050ac93ff7ef"},{"version":"CommandV1","origId":1270,"guid":"607ab942-687b-410b-ae23-f45ec8ab2739","subtype":"command","commandType":"auto","position":3.96875,"command":"%md ## Explicit Model Binary Tuning lambda","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5028e337-460f-430d-be86-51d7963ebd44"},{"version":"CommandV1","origId":1271,"guid":"18309dda-f131-43a3-a50b-6cab68584996","subtype":"command","commandType":"auto","position":3.97265625,"command":"# Normalize ratings\nratings_normalized = ratings_full.map(lambda x: Rating(x[0], x[1], 1.0))\n\n# Perform parameter tuning using grid search\nparam_grid = {'rank': [100], \n              'iterations': [10],\n              'lambda_': [.01]\n}\nparams = {'rank': 50, 'iterations': 5, 'lambda_': 100.0}\n\n# Run grid search\nmodel = als_recommender()\nmodel_results = grid_search_cv(model, ratings_normalized, param_grid, n_folds=2, threaded=False)\n#output_results(model_results, model.name + '_vs_lambda_normalized')\noutput_results(model_results)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Running 2 fold cv with params:\n{&apos;lambda_&apos;: 100.0, &apos;rank&apos;: 100, &apos;iterations&apos;: 10}\nmodel results: [{&apos;mAP_mean&apos;: 9.0900973674619867e-05, &apos;lambda_&apos;: 100.0, &apos;rank&apos;: 100, &apos;iterations&apos;: 10, &apos;mAP_std&apos;: 1.4230190850538191e-05}]\nbest results: {&apos;mAP_mean&apos;: 9.0900973674619867e-05, &apos;lambda_&apos;: 100.0, &apos;rank&apos;: 100, &apos;iterations&apos;: 10, &apos;mAP_std&apos;: 1.4230190850538191e-05}\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 26176.0 failed 4 times, most recent failure: Lost task 16.3 in stage 26176.0 (TID 12553192, 10.172.232.21): java.lang.AssertionError: assertion failed: lapack.dppsv returned 4.","error":"<div class=\"ansiout\">Running 2 fold cv with params:\n{&apos;lambda_&apos;: 0.0, &apos;iterations&apos;: 5, &apos;rank&apos;: 50}\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-15-ffefab9d0f74&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     11</span> <span class=\"ansired\"># Run grid search</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     12</span> model <span class=\"ansiyellow\">=</span> als_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 13</span><span class=\"ansiyellow\"> </span>perform_cross_validation<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings_full<span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">2</span><span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">=</span>False<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">=</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     14</span> <span class=\"ansired\">#model_results = grid_search_cv(model, ratings_normalized, param_grid, n_folds=2, threaded=False)</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     15</span> <span class=\"ansired\">#output_results(model_results, model.name + &apos;_vs_lambda_normalized&apos;)</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-3-03fd2517dd95&gt;</span> in <span class=\"ansicyan\">perform_cross_validation</span><span class=\"ansiblue\">(model, ratings, n_folds, threaded, params)</span>\n<span class=\"ansigreen\">     83</span>   <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     84</span>     <span class=\"ansigreen\">for</span> i <span class=\"ansigreen\">in</span> range<span class=\"ansiyellow\">(</span>n_folds<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 85</span><span class=\"ansiyellow\">       </span>mAP_scores<span class=\"ansiyellow\">.</span>append<span class=\"ansiyellow\">(</span>evaluate_model<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> kf<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">,</span> i<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     86</span>   mAP_mean <span class=\"ansiyellow\">=</span> mean<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">[</span>x<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span> <span class=\"ansigreen\">for</span> x <span class=\"ansigreen\">in</span> mAP_scores<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     87</span>   mAP_std <span class=\"ansiyellow\">=</span> std<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">[</span>x<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span> <span class=\"ansigreen\">for</span> x <span class=\"ansigreen\">in</span> mAP_scores<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-3-03fd2517dd95&gt;</span> in <span class=\"ansicyan\">evaluate_model</span><span class=\"ansiblue\">(model, ratings, kfolds, params, fold_i)</span>\n<span class=\"ansigreen\">     47</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     48</span>   <span class=\"ansired\"># Train the model</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 49</span><span class=\"ansiyellow\">   </span>model<span class=\"ansiyellow\">.</span>train_model<span class=\"ansiyellow\">(</span>train_and_test_visible<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     50</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     51</span>   <span class=\"ansired\"># HACK :Get a subset of test users to get recommendations</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-3-03fd2517dd95&gt;</span> in <span class=\"ansicyan\">train_model</span><span class=\"ansiblue\">(self, data, params)</span>\n<span class=\"ansigreen\">    138</span>   <span class=\"ansigreen\">def</span> train_model<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> data<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    139</span>     <span class=\"ansiblue\">&quot;&quot;&quot;Train on the data&quot;&quot;&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 140</span><span class=\"ansiyellow\">     </span>self<span class=\"ansiyellow\">.</span>model <span class=\"ansiyellow\">=</span> ALS<span class=\"ansiyellow\">.</span>train<span class=\"ansiyellow\">(</span>data<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    141</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    142</span>   <span class=\"ansigreen\">def</span> get_predictions<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> users<span class=\"ansiyellow\">,</span> products<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/mllib/recommendation.pyc</span> in <span class=\"ansicyan\">train</span><span class=\"ansiblue\">(cls, ratings, rank, iterations, lambda_, blocks, nonnegative, seed)</span>\n<span class=\"ansigreen\">    271</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    272</span>         model = callMLlibFunc(&quot;trainALSModel&quot;, cls._prepare(ratings), rank, iterations,\n<span class=\"ansigreen\">--&gt; 273</span><span class=\"ansiyellow\">                               lambda_, blocks, nonnegative, seed)\n</span><span class=\"ansigreen\">    274</span>         <span class=\"ansigreen\">return</span> MatrixFactorizationModel<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    275</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/mllib/common.pyc</span> in <span class=\"ansicyan\">callMLlibFunc</span><span class=\"ansiblue\">(name, *args)</span>\n<span class=\"ansigreen\">    128</span>     sc <span class=\"ansiyellow\">=</span> SparkContext<span class=\"ansiyellow\">.</span>getOrCreate<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    129</span>     api <span class=\"ansiyellow\">=</span> getattr<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">.</span>_jvm<span class=\"ansiyellow\">.</span>PythonMLLibAPI<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 130</span><span class=\"ansiyellow\">     </span><span class=\"ansigreen\">return</span> callJavaFunc<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">,</span> api<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">*</span>args<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    131</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    132</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/mllib/common.pyc</span> in <span class=\"ansicyan\">callJavaFunc</span><span class=\"ansiblue\">(sc, func, *args)</span>\n<span class=\"ansigreen\">    121</span>     <span class=\"ansiblue\">&quot;&quot;&quot; Call Java Function &quot;&quot;&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    122</span>     args <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span>_py2java<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">,</span> a<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">for</span> a <span class=\"ansigreen\">in</span> args<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 123</span><span class=\"ansiyellow\">     </span><span class=\"ansigreen\">return</span> _java2py<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">,</span> func<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>args<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    124</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    125</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1131</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1132</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1133</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1134</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1135</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.pyc</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    317</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    318</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 319</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    320</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    321</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o2126.trainALSModel.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 16 in stage 26176.0 failed 4 times, most recent failure: Lost task 16.3 in stage 26176.0 (TID 12553192, 10.172.232.21): java.lang.AssertionError: assertion failed: lapack.dppsv returned 4.\n\tat scala.Predef$.assert(Predef.scala:179)\n\tat org.apache.spark.mllib.linalg.CholeskyDecomposition$.solve(CholeskyDecomposition.scala:40)\n\tat org.apache.spark.ml.recommendation.ALS$CholeskySolver.solve(ALS.scala:537)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$org$apache$spark$ml$recommendation$ALS$$computeFactors$1.apply(ALS.scala:1318)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$org$apache$spark$ml$recommendation$ALS$$computeFactors$1.apply(ALS.scala:1279)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$43$$anonfun$apply$44.apply(PairRDDFunctions.scala:759)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$43$$anonfun$apply$44.apply(PairRDDFunctions.scala:759)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:155)\n\tat org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)\n\tat org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:86)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1891)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1904)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1917)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1134)\n\tat org.apache.spark.mllib.recommendation.ALS.run(ALS.scala:276)\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainALSModel(PythonMLLibAPI.scala:488)\n\tat sun.reflect.GeneratedMethodAccessor172.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.AssertionError: assertion failed: lapack.dppsv returned 4.\n\tat scala.Predef$.assert(Predef.scala:179)\n\tat org.apache.spark.mllib.linalg.CholeskyDecomposition$.solve(CholeskyDecomposition.scala:40)\n\tat org.apache.spark.ml.recommendation.ALS$CholeskySolver.solve(ALS.scala:537)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$org$apache$spark$ml$recommendation$ALS$$computeFactors$1.apply(ALS.scala:1318)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$org$apache$spark$ml$recommendation$ALS$$computeFactors$1.apply(ALS.scala:1279)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$43$$anonfun$apply$44.apply(PairRDDFunctions.scala:759)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$43$$anonfun$apply$44.apply(PairRDDFunctions.scala:759)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:155)\n\tat org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)\n\tat org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)\n\tat org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:283)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:86)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n\n</div>","workflows":[],"startTime":1.482005826393E12,"submitTime":1.482005824181E12,"finishTime":1.482006545306E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"91a5cf57-81eb-4c85-b112-1dcdf83b8ba7"},{"version":"CommandV1","origId":1272,"guid":"7e387e03-75f4-4d92-b186-ec71d1e914a5","subtype":"command","commandType":"auto","position":3.9736328125,"command":"print ratings_normalized.take(10)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">[Rating(user=6868, product=328474, rating=1.0), Rating(user=6868, product=277613, rating=1.0), Rating(user=6868, product=205995, rating=1.0), Rating(user=6868, product=115196, rating=1.0), Rating(user=6868, product=292298, rating=1.0), Rating(user=6868, product=314350, rating=1.0), Rating(user=6868, product=238809, rating=1.0), Rating(user=6868, product=309748, rating=1.0), Rating(user=6868, product=362235, rating=1.0), Rating(user=6868, product=191533, rating=1.0)]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.481999753585E12,"submitTime":1.481999751646E12,"finishTime":1.481999753706E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"29d70976-bdc8-4cc4-b75b-4c5f0256526c"},{"version":"CommandV1","origId":1273,"guid":"f176c07d-c7d6-4076-a515-956c914ef927","subtype":"command","commandType":"auto","position":3.974609375,"command":"%md ## Explicit Model Binary vs. Rank","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ea001124-b3bb-4d8f-a2ce-609060353b59"},{"version":"CommandV1","origId":1274,"guid":"3edfc280-ab7f-4151-9094-d39ce15953c0","subtype":"command","commandType":"auto","position":3.9765625,"command":"# Normalize ratings\nratings_normalized = ratings.map(lambda x: Rating(x[0], x[1], x[2]/x[2]))\n\n# Perform parameter tuning using grid search\nparam_grid = {'rank': [10, 20, 30, 40, 50], \n              'iterations': [5],\n              'lambda_': [500.]\n}\n\n# Run grid search\nmodel = als_recommender()\nmodel_results = grid_search_cv(model, ratings_normalized, param_grid, n_folds=5, threaded=False)\noutput_results(model_results, model.name + '_vs_rank_normalized')","commandVersion":0,"state":"finished","results":null,"errorSummary":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 41867.0 failed 4 times, most recent failure: Lost task 9.3 in stage 41867.0 (TID 1556340, 10.172.245.58): java.io.IOException: No space left on device","error":"<div class=\"ansiout\">Running 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 20, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 10, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 40, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;lambda_&apos;: 500.0, &apos;rank&apos;: 30, &apos;iterations&apos;: 5}\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-92-7f1ca8200a8b&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     10</span> <span class=\"ansired\"># Run grid search</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     11</span> model <span class=\"ansiyellow\">=</span> als_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 12</span><span class=\"ansiyellow\"> </span>model_results <span class=\"ansiyellow\">=</span> grid_search_cv<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings_normalized<span class=\"ansiyellow\">,</span> param_grid<span class=\"ansiyellow\">,</span> n_folds <span class=\"ansiyellow\">=</span> <span class=\"ansicyan\">5</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     13</span> <span class=\"ansigreen\">print</span> <span class=\"ansiblue\">&quot;model results:&quot;</span><span class=\"ansiyellow\">,</span> model_results<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     14</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-88-7d9197424e7b&gt;</span> in <span class=\"ansicyan\">grid_search_cv</span><span class=\"ansiblue\">(model, ratings, param_grid, n_folds, threaded)</span>\n<span class=\"ansigreen\">    122</span>   <span class=\"ansigreen\">if</span> threaded<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    123</span>     tpool <span class=\"ansiyellow\">=</span> ThreadPool<span class=\"ansiyellow\">(</span>processes<span class=\"ansiyellow\">=</span>len<span class=\"ansiyellow\">(</span>params_list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 124</span><span class=\"ansiyellow\">     </span>results <span class=\"ansiyellow\">=</span> tpool<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>partial<span class=\"ansiyellow\">(</span>perform_cross_validation<span class=\"ansiyellow\">,</span> model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> n_folds<span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> params_list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    125</span>   <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    126</span>     <span class=\"ansigreen\">for</span> params <span class=\"ansigreen\">in</span> params_list<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">map</span><span class=\"ansiblue\">(self, func, iterable, chunksize)</span>\n<span class=\"ansigreen\">    249</span>         &apos;&apos;&apos;\n<span class=\"ansigreen\">    250</span>         <span class=\"ansigreen\">assert</span> self<span class=\"ansiyellow\">.</span>_state <span class=\"ansiyellow\">==</span> RUN<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 251</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>map_async<span class=\"ansiyellow\">(</span>func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>get<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    252</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    253</span>     <span class=\"ansigreen\">def</span> imap<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">get</span><span class=\"ansiblue\">(self, timeout)</span>\n<span class=\"ansigreen\">    565</span>             <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    566</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 567</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    568</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    569</span>     <span class=\"ansigreen\">def</span> _set<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> i<span class=\"ansiyellow\">,</span> obj<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o66609.trainALSModel.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 41867.0 failed 4 times, most recent failure: Lost task 9.3 in stage 41867.0 (TID 1556340, 10.172.245.58): java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flush(LZ4BlockOutputStream.java:225)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.flush(ObjectOutputStream.java:1823)\n\tat java.io.ObjectOutputStream.flush(ObjectOutputStream.java:719)\n\tat org.apache.spark.serializer.JavaSerializationStream.flush(JavaSerializer.scala:56)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.commitAndClose(DiskBlockObjectWriter.scala:130)\n\tat org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:714)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:86)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1891)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1904)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1917)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1134)\n\tat org.apache.spark.mllib.recommendation.ALS.run(ALS.scala:276)\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainALSModel(PythonMLLibAPI.scala:488)\n\tat sun.reflect.GeneratedMethodAccessor182.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flush(LZ4BlockOutputStream.java:225)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.flush(ObjectOutputStream.java:1823)\n\tat java.io.ObjectOutputStream.flush(ObjectOutputStream.java:719)\n\tat org.apache.spark.serializer.JavaSerializationStream.flush(JavaSerializer.scala:56)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.commitAndClose(DiskBlockObjectWriter.scala:130)\n\tat org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:714)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:86)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n\n</div>","workflows":[],"startTime":1.48176902894E12,"submitTime":1.48176902894E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7ed3977a-e845-4efa-b7be-cfe3decc523c"},{"version":"CommandV1","origId":1275,"guid":"9357e3b5-2624-4a33-ade9-2d050e227ef0","subtype":"command","commandType":"auto","position":3.9921875,"command":"%md ## Implicit Model Parameter Tuning alpha","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"83514ea5-f08b-4c1b-8214-843b9a57d084"},{"version":"CommandV1","origId":1276,"guid":"3e7ed5b4-26af-43c4-8975-77ee8a345fc8","subtype":"command","commandType":"auto","position":3.994140625,"command":"# Perform parameter tuning using grid search\nparam_grid = {'rank': [50], \n              'iterations': [5],\n              'alpha': [0., 1., 20., 40., 80.,],\n              'lambda_': [1.0]\n}\n\n# Run grid search\nmodel = implicit_recommender()\nmodel_results = grid_search_cv(model, ratings, param_grid, n_folds=5, threaded=False)\noutput_results(model_results, model.name + '_vs_alpha_final')","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Running 5 fold cv with params:\n{&apos;alpha&apos;: 0.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 1.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 20.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 80.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nmodel results: [{&apos;mAP_mean&apos;: 0.00013541461339641145, &apos;rank&apos;: 50, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 9.0228442202564744e-05, &apos;alpha&apos;: 0.0}, {&apos;mAP_mean&apos;: 0.049933158595563132, &apos;rank&apos;: 50, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0027702797940851592, &apos;alpha&apos;: 1.0}, {&apos;mAP_mean&apos;: 0.091241359702426958, &apos;rank&apos;: 50, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.010470994696498074, &apos;alpha&apos;: 20.0}, {&apos;mAP_mean&apos;: 0.095976234756939602, &apos;rank&apos;: 50, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.014298856881234702, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.08628374863791495, &apos;rank&apos;: 50, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0027462596968941102, &apos;alpha&apos;: 80.0}]\nbest results: {&apos;mAP_mean&apos;: 0.095976234756939602, &apos;rank&apos;: 50, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.014298856881234702, &apos;alpha&apos;: 40.0}\nSaving results to file...\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 205 in stage 7987.0 failed 4 times, most recent failure: Lost task 205.3 in stage 7987.0 (TID 357694, 10.172.233.116): java.io.IOException: No space left on device","error":"<div class=\"ansiout\">Running 5 fold cv with params:\n{&apos;alpha&apos;: 0.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 1.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 20.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 80.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-4-90722c65e3c4&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      8</span> <span class=\"ansired\"># Run grid search</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      9</span> model <span class=\"ansiyellow\">=</span> implicit_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 10</span><span class=\"ansiyellow\"> </span>model_results <span class=\"ansiyellow\">=</span> grid_search_cv<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> param_grid<span class=\"ansiyellow\">,</span> n_folds<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">5</span><span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">=</span>False<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     11</span> output_results<span class=\"ansiyellow\">(</span>model_results<span class=\"ansiyellow\">,</span> model<span class=\"ansiyellow\">.</span>name <span class=\"ansiyellow\">+</span> <span class=\"ansiblue\">&apos;_vs_alpha_final&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-3-553f15669daf&gt;</span> in <span class=\"ansicyan\">grid_search_cv</span><span class=\"ansiblue\">(model, ratings, param_grid, n_folds, threaded)</span>\n<span class=\"ansigreen\">    113</span>   <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    114</span>     <span class=\"ansigreen\">for</span> params <span class=\"ansigreen\">in</span> params_list<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 115</span><span class=\"ansiyellow\">       </span>results<span class=\"ansiyellow\">.</span>append<span class=\"ansiyellow\">(</span>perform_cross_validation<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> n_folds<span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    116</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    117</span>   <span class=\"ansigreen\">return</span> results<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-3-553f15669daf&gt;</span> in <span class=\"ansicyan\">perform_cross_validation</span><span class=\"ansiblue\">(model, ratings, n_folds, threaded, params)</span>\n<span class=\"ansigreen\">     92</span>   <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     93</span>     <span class=\"ansigreen\">for</span> i <span class=\"ansigreen\">in</span> range<span class=\"ansiyellow\">(</span>n_folds<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 94</span><span class=\"ansiyellow\">       </span>mAP_scores<span class=\"ansiyellow\">.</span>append<span class=\"ansiyellow\">(</span>evaluate_model<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> kf<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">,</span> i<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     95</span>   mAP_mean <span class=\"ansiyellow\">=</span> mean<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">[</span>x<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span> <span class=\"ansigreen\">for</span> x <span class=\"ansigreen\">in</span> mAP_scores<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     96</span>   mAP_std <span class=\"ansiyellow\">=</span> std<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">[</span>x<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span> <span class=\"ansigreen\">for</span> x <span class=\"ansigreen\">in</span> mAP_scores<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-3-553f15669daf&gt;</span> in <span class=\"ansicyan\">evaluate_model</span><span class=\"ansiblue\">(model, ratings, kfolds, params, fold_i)</span>\n<span class=\"ansigreen\">     49</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     50</span>   <span class=\"ansired\"># Train the model</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 51</span><span class=\"ansiyellow\">   </span>model<span class=\"ansiyellow\">.</span>train_model<span class=\"ansiyellow\">(</span>train_and_test_visible<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     52</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     53</span>   <span class=\"ansired\"># HACK :Get a subset of test users to get recommendations</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-3-553f15669daf&gt;</span> in <span class=\"ansicyan\">train_model</span><span class=\"ansiblue\">(self, data, params)</span>\n<span class=\"ansigreen\">    174</span>   <span class=\"ansigreen\">def</span> train_model<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> data<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    175</span>     <span class=\"ansiblue\">&quot;&quot;&quot;Train on the data&quot;&quot;&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 176</span><span class=\"ansiyellow\">     </span>self<span class=\"ansiyellow\">.</span>model <span class=\"ansiyellow\">=</span> ALS<span class=\"ansiyellow\">.</span>trainImplicit<span class=\"ansiyellow\">(</span>data<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    177</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    178</span> <span class=\"ansigreen\">class</span> popularity_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/mllib/recommendation.py</span> in <span class=\"ansicyan\">trainImplicit</span><span class=\"ansiblue\">(cls, ratings, rank, iterations, lambda_, blocks, alpha, nonnegative, seed)</span>\n<span class=\"ansigreen\">    312</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    313</span>         model = callMLlibFunc(&quot;trainImplicitALSModel&quot;, cls._prepare(ratings), rank,\n<span class=\"ansigreen\">--&gt; 314</span><span class=\"ansiyellow\">                               iterations, lambda_, blocks, alpha, nonnegative, seed)\n</span><span class=\"ansigreen\">    315</span>         <span class=\"ansigreen\">return</span> MatrixFactorizationModel<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    316</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/mllib/common.pyc</span> in <span class=\"ansicyan\">callMLlibFunc</span><span class=\"ansiblue\">(name, *args)</span>\n<span class=\"ansigreen\">    128</span>     sc <span class=\"ansiyellow\">=</span> SparkContext<span class=\"ansiyellow\">.</span>getOrCreate<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    129</span>     api <span class=\"ansiyellow\">=</span> getattr<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">.</span>_jvm<span class=\"ansiyellow\">.</span>PythonMLLibAPI<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 130</span><span class=\"ansiyellow\">     </span><span class=\"ansigreen\">return</span> callJavaFunc<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">,</span> api<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">*</span>args<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    131</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    132</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/mllib/common.pyc</span> in <span class=\"ansicyan\">callJavaFunc</span><span class=\"ansiblue\">(sc, func, *args)</span>\n<span class=\"ansigreen\">    121</span>     <span class=\"ansiblue\">&quot;&quot;&quot; Call Java Function &quot;&quot;&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    122</span>     args <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span>_py2java<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">,</span> a<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">for</span> a <span class=\"ansigreen\">in</span> args<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 123</span><span class=\"ansiyellow\">     </span><span class=\"ansigreen\">return</span> _java2py<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">,</span> func<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>args<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    124</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    125</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1131</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1132</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1133</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1134</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1135</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.pyc</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    317</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    318</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 319</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    320</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    321</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o6347.trainImplicitALSModel.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 205 in stage 7987.0 failed 4 times, most recent failure: Lost task 205.3 in stage 7987.0 (TID 357694, 10.172.233.116): java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flush(LZ4BlockOutputStream.java:225)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.flush(ObjectOutputStream.java:1823)\n\tat java.io.ObjectOutputStream.flush(ObjectOutputStream.java:719)\n\tat org.apache.spark.serializer.JavaSerializationStream.flush(JavaSerializer.scala:56)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.commitAndClose(DiskBlockObjectWriter.scala:130)\n\tat org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:714)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:86)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1891)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1904)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1917)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1134)\n\tat org.apache.spark.mllib.recommendation.ALS.run(ALS.scala:276)\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainImplicitALSModel(PythonMLLibAPI.scala:519)\n\tat sun.reflect.GeneratedMethodAccessor153.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flush(LZ4BlockOutputStream.java:225)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.flush(ObjectOutputStream.java:1823)\n\tat java.io.ObjectOutputStream.flush(ObjectOutputStream.java:719)\n\tat org.apache.spark.serializer.JavaSerializationStream.flush(JavaSerializer.scala:56)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.commitAndClose(DiskBlockObjectWriter.scala:130)\n\tat org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:714)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:86)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n\n</div>","workflows":[],"startTime":1.481775871173E12,"submitTime":1.481775536109E12,"finishTime":1.481779384253E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8197f88b-6860-4e03-b140-3bbc14063cc7"},{"version":"CommandV1","origId":1277,"guid":"8fdaf42e-8c7f-4667-a377-a3bab50568c6","subtype":"command","commandType":"auto","position":3.99609375,"command":"%md ## Implicit Model Parameter Tuning lambda","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"341cfc61-c58c-4c1b-a4c3-f7c9116ed940"},{"version":"CommandV1","origId":1278,"guid":"8e0aeae2-de4d-4ace-a4b6-247f72f2ba82","subtype":"command","commandType":"auto","position":3.998046875,"command":"# NOTE: USE TUNED ALPHA = 40.0\n# Perform parameter tuning using grid search\nparam_grid = {'rank': [50], \n              'iterations': [5],\n              'alpha': [40.0],\n              'lambda_': [0., 0.01, 0.1, 1., 10.]\n}\n\n# Run grid search\nmodel = implicit_recommender()\nmodel_results = grid_search_cv(model, ratings, param_grid, n_folds=5, threaded=False)\noutput_results(model_results, model.name + '_vs_lambda_final')","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Running 5 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 0.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 0.01, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 0.1, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 10.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nmodel results: [{&apos;mAP_mean&apos;: 0.096713279361941393, &apos;rank&apos;: 50, &apos;lambda_&apos;: 0.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.012583792231912385, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.090388703956550437, &apos;rank&apos;: 50, &apos;lambda_&apos;: 0.01, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0056608719061246411, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.10070151760009446, &apos;rank&apos;: 50, &apos;lambda_&apos;: 0.1, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.016768862508302746, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.095902698613243922, &apos;rank&apos;: 50, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.003098816482509589, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.083854325789194203, &apos;rank&apos;: 50, &apos;lambda_&apos;: 10.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0097720948949417425, &apos;alpha&apos;: 40.0}]\nbest results: {&apos;mAP_mean&apos;: 0.10070151760009446, &apos;rank&apos;: 50, &apos;lambda_&apos;: 0.1, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.016768862508302746, &apos;alpha&apos;: 40.0}\nSaving results to file...\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">TypeError</span>: train() got an unexpected keyword argument &apos;alpha&apos;","error":"<div class=\"ansiout\">Running 5 fold cv with params:\n{&apos;alpha&apos;: 0.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 30.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 20.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 10.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 50.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 5 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-84-9a1205472f0c&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      8</span> <span class=\"ansired\"># Run grid search</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      9</span> model <span class=\"ansiyellow\">=</span> als_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 10</span><span class=\"ansiyellow\"> </span>model_results <span class=\"ansiyellow\">=</span> grid_search_cv<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> param_grid<span class=\"ansiyellow\">,</span> n_folds <span class=\"ansiyellow\">=</span> <span class=\"ansicyan\">5</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     11</span> <span class=\"ansigreen\">print</span> <span class=\"ansiblue\">&quot;model results:&quot;</span><span class=\"ansiyellow\">,</span> model_results<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     12</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-69-7d9197424e7b&gt;</span> in <span class=\"ansicyan\">grid_search_cv</span><span class=\"ansiblue\">(model, ratings, param_grid, n_folds, threaded)</span>\n<span class=\"ansigreen\">    122</span>   <span class=\"ansigreen\">if</span> threaded<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    123</span>     tpool <span class=\"ansiyellow\">=</span> ThreadPool<span class=\"ansiyellow\">(</span>processes<span class=\"ansiyellow\">=</span>len<span class=\"ansiyellow\">(</span>params_list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 124</span><span class=\"ansiyellow\">     </span>results <span class=\"ansiyellow\">=</span> tpool<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>partial<span class=\"ansiyellow\">(</span>perform_cross_validation<span class=\"ansiyellow\">,</span> model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> n_folds<span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> params_list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    125</span>   <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    126</span>     <span class=\"ansigreen\">for</span> params <span class=\"ansigreen\">in</span> params_list<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">map</span><span class=\"ansiblue\">(self, func, iterable, chunksize)</span>\n<span class=\"ansigreen\">    249</span>         &apos;&apos;&apos;\n<span class=\"ansigreen\">    250</span>         <span class=\"ansigreen\">assert</span> self<span class=\"ansiyellow\">.</span>_state <span class=\"ansiyellow\">==</span> RUN<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 251</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>map_async<span class=\"ansiyellow\">(</span>func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>get<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    252</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    253</span>     <span class=\"ansigreen\">def</span> imap<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">get</span><span class=\"ansiblue\">(self, timeout)</span>\n<span class=\"ansigreen\">    565</span>             <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    566</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 567</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    568</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    569</span>     <span class=\"ansigreen\">def</span> _set<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> i<span class=\"ansiyellow\">,</span> obj<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TypeError</span>: train() got an unexpected keyword argument &apos;alpha&apos;\n</div>","workflows":[],"startTime":1.481779384286E12,"submitTime":1.4817755386E12,"finishTime":1.481782898392E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"71a2a766-c36f-47a6-a1ae-81a646aad88e"},{"version":"CommandV1","origId":1279,"guid":"303b2d6e-9ba4-4949-b3eb-cd7a8cde251b","subtype":"command","commandType":"auto","position":3.99853515625,"command":"%md ## Final Model vs. Rank","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1fc7d83b-de8c-4295-b6b7-10c672ba03a8"},{"version":"CommandV1","origId":1280,"guid":"cac7900e-bdaf-49af-ad6e-6a9d28c53d61","subtype":"command","commandType":"auto","position":3.9990234375,"command":"# Perform parameter tuning using grid search\nparam_grid = {'rank': [10, 20, 30, 40, 50], \n              'iterations': [5],\n              'alpha': [40.],\n              'lambda_': [1.0]\n}\n\n# Run grid search\nmodel = implicit_recommender()\nmodel_results = grid_search_cv(model, ratings, param_grid, n_folds=2, threaded=True)\noutput_results(model_results, model.name + '_vs_rank_latest')","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Running 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 10, &apos;iterations&apos;: 5}\nRunning 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 40, &apos;iterations&apos;: 5}\nRunning 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 50, &apos;iterations&apos;: 5}\nRunning 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 30, &apos;iterations&apos;: 5}\nRunning 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 20, &apos;iterations&apos;: 5}\nmodel results: [{&apos;mAP_mean&apos;: 0.042818143294447941, &apos;rank&apos;: 10, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0012160205423215643, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.072108895581868754, &apos;rank&apos;: 20, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0240764110999474, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.071031999451596273, &apos;rank&apos;: 30, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0037204154353642979, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.065745801500918299, &apos;rank&apos;: 40, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0189075461060653, &apos;alpha&apos;: 40.0}, {&apos;mAP_mean&apos;: 0.089934819186371598, &apos;rank&apos;: 50, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0030112661986139155, &apos;alpha&apos;: 40.0}]\nbest results: {&apos;mAP_mean&apos;: 0.089934819186371598, &apos;rank&apos;: 50, &apos;lambda_&apos;: 1.0, &apos;iterations&apos;: 5, &apos;mAP_std&apos;: 0.0030112661986139155, &apos;alpha&apos;: 40.0}\nSaving results to file...\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 108 in stage 16360.0 failed 4 times, most recent failure: Lost task 108.3 in stage 16360.0 (TID 744065, 10.172.233.125): java.io.IOException: No space left on device","error":null,"workflows":[],"startTime":1.481990558097E12,"submitTime":1.481990539694E12,"finishTime":1.481992602562E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"4063b22e-7250-4130-9498-2c3cfe8ff74d"},{"version":"CommandV1","origId":1281,"guid":"4aeeb986-ff28-495d-8489-19edcc066445","subtype":"command","commandType":"auto","position":3.999267578125,"command":"# Perform parameter tuning using grid search\nparam_grid = {'rank': [200], \n              'iterations': [5],\n              'alpha': [40.],\n              'lambda_': [1.0]\n}\n\n# Run grid search\nmodel = implicit_recommender()\nmodel_results = grid_search_cv(model, ratings_full, param_grid, n_folds=2, threaded=True)\noutput_results(model_results)","commandVersion":0,"state":"error","results":null,"errorSummary":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 58 in stage 1204.0 failed 4 times, most recent failure: Lost task 58.3 in stage 1204.0 (TID 53121, 10.172.225.31): java.io.IOException: No space left on device","error":"<div class=\"ansiout\">Running 2 fold cv with params:\n{&apos;alpha&apos;: 40.0, &apos;lambda_&apos;: 1.0, &apos;rank&apos;: 200, &apos;iterations&apos;: 5}\n<span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-5-b37ab2a0e284&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      8</span> <span class=\"ansired\"># Run grid search</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      9</span> model <span class=\"ansiyellow\">=</span> implicit_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 10</span><span class=\"ansiyellow\"> </span>model_results <span class=\"ansiyellow\">=</span> grid_search_cv<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">,</span> ratings_full<span class=\"ansiyellow\">,</span> param_grid<span class=\"ansiyellow\">,</span> n_folds<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">2</span><span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">=</span>True<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     11</span> output_results<span class=\"ansiyellow\">(</span>model_results<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-3-03fd2517dd95&gt;</span> in <span class=\"ansicyan\">grid_search_cv</span><span class=\"ansiblue\">(model, ratings, param_grid, n_folds, threaded)</span>\n<span class=\"ansigreen\">    101</span>   <span class=\"ansigreen\">if</span> threaded<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    102</span>     tpool <span class=\"ansiyellow\">=</span> ThreadPool<span class=\"ansiyellow\">(</span>processes<span class=\"ansiyellow\">=</span>len<span class=\"ansiyellow\">(</span>params_list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 103</span><span class=\"ansiyellow\">     </span>results <span class=\"ansiyellow\">=</span> tpool<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span>partial<span class=\"ansiyellow\">(</span>perform_cross_validation<span class=\"ansiyellow\">,</span> model<span class=\"ansiyellow\">,</span> ratings<span class=\"ansiyellow\">,</span> n_folds<span class=\"ansiyellow\">,</span> threaded<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> params_list<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    104</span>   <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    105</span>     <span class=\"ansigreen\">for</span> params <span class=\"ansigreen\">in</span> params_list<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">map</span><span class=\"ansiblue\">(self, func, iterable, chunksize)</span>\n<span class=\"ansigreen\">    249</span>         &apos;&apos;&apos;\n<span class=\"ansigreen\">    250</span>         <span class=\"ansigreen\">assert</span> self<span class=\"ansiyellow\">.</span>_state <span class=\"ansiyellow\">==</span> RUN<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 251</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>map_async<span class=\"ansiyellow\">(</span>func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>get<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    252</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    253</span>     <span class=\"ansigreen\">def</span> imap<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> func<span class=\"ansiyellow\">,</span> iterable<span class=\"ansiyellow\">,</span> chunksize<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/usr/lib/python2.7/multiprocessing/pool.pyc</span> in <span class=\"ansicyan\">get</span><span class=\"ansiblue\">(self, timeout)</span>\n<span class=\"ansigreen\">    565</span>             <span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    566</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 567</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> self<span class=\"ansiyellow\">.</span>_value<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    568</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    569</span>     <span class=\"ansigreen\">def</span> _set<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> i<span class=\"ansiyellow\">,</span> obj<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o403.trainImplicitALSModel.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 58 in stage 1204.0 failed 4 times, most recent failure: Lost task 58.3 in stage 1204.0 (TID 53121, 10.172.225.31): java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:205)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:158)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.writeByte(ObjectOutputStream.java:1915)\n\tat java.io.ObjectOutputStream.writeFatalException(ObjectOutputStream.java:1576)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:351)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:135)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:185)\n\tat org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$1.writeNext(WritablePartitionedPairCollection.scala:56)\n\tat org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:712)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:86)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1891)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1954)\n\tat org.apache.spark.rdd.RDD$$anonfun$aggregate$1.apply(RDD.scala:1091)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:358)\n\tat org.apache.spark.rdd.RDD.aggregate(RDD.scala:1084)\n\tat org.apache.spark.ml.recommendation.ALS$.computeYtY(ALS.scala:1330)\n\tat org.apache.spark.ml.recommendation.ALS$.org$apache$spark$ml$recommendation$ALS$$computeFactors(ALS.scala:1271)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$train$3.apply(ALS.scala:733)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$train$3.apply(ALS.scala:720)\n\tat scala.collection.immutable.Range.foreach(Range.scala:141)\n\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:720)\n\tat org.apache.spark.mllib.recommendation.ALS.run(ALS.scala:252)\n\tat org.apache.spark.mllib.api.python.PythonMLLibAPI.trainImplicitALSModel(PythonMLLibAPI.scala:519)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.IOException: No space left on device\n\tat java.io.FileOutputStream.writeBytes(Native Method)\n\tat java.io.FileOutputStream.write(FileOutputStream.java:326)\n\tat org.apache.spark.storage.TimeTrackingOutputStream.write(TimeTrackingOutputStream.java:58)\n\tat java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)\n\tat java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:205)\n\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:158)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\n\tat java.io.ObjectOutputStream$BlockDataOutputStream.writeByte(ObjectOutputStream.java:1915)\n\tat java.io.ObjectOutputStream.writeFatalException(ObjectOutputStream.java:1576)\n\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:351)\n\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)\n\tat org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:135)\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:185)\n\tat org.apache.spark.util.collection.WritablePartitionedPairCollection$$anon$1.writeNext(WritablePartitionedPairCollection.scala:56)\n\tat org.apache.spark.util.collection.ExternalSorter.writePartitionedFile(ExternalSorter.scala:712)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:72)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:86)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n\n</div>","workflows":[],"startTime":1.482025926521E12,"submitTime":1.482025926521E12,"finishTime":1.482029020182E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ab5afc2e-1935-4019-9b1f-9b2efeeb9c70"},{"version":"CommandV1","origId":1282,"guid":"937e574f-9c90-4f2f-9b82-a303059eb544","subtype":"command","commandType":"auto","position":3.99951171875,"command":"%md # Save Final Model","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"dc851660-7a38-44cd-9976-0b82b6730c59"},{"version":"CommandV1","origId":1283,"guid":"88f958bc-21a7-4ed9-bf69-8120be548da1","subtype":"command","commandType":"auto","position":3.999755859375,"command":"# Retrain model on all data\nmodel = implicit_recommender()\nbest_params = {'rank': 50, \n              'iterations': 5,\n              'alpha': 40.,\n              'lambda_': 1.0\n}\n\nmodel.train_model(ratings, best_params)\n\n# Output the final model\npath_to_models = '/mnt/S3/models'\nfile_name = 'good_model'\nmodel.save(os.path.join(path_to_models, file_name))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Saving model to file...\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;implicit_recommender&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-4-cb9a07cc6e68&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Retrain model on all data</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>model <span class=\"ansiyellow\">=</span> implicit_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> best_params = {&apos;rank&apos;: 50, \n<span class=\"ansigreen\">      4</span>               <span class=\"ansiblue\">&apos;iterations&apos;</span><span class=\"ansiyellow\">:</span> <span class=\"ansicyan\">5</span><span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span>               <span class=\"ansiblue\">&apos;alpha&apos;</span><span class=\"ansiyellow\">:</span> <span class=\"ansicyan\">40.</span><span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;implicit_recommender&apos; is not defined\n</div>","workflows":[],"startTime":1.481905009943E12,"submitTime":1.481905008637E12,"finishTime":1.481905395668E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fcbc5ac5-2148-48e9-9ed2-8b0533c9d329"},{"version":"CommandV1","origId":1284,"guid":"0c944b90-ef22-4ad0-a982-5d613c649677","subtype":"command","commandType":"auto","position":3.9998779296875,"command":"%md # Save Custom Model with Spotify Users","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c3da93c0-7e6d-4d5f-a509-9bfccb5204aa"},{"version":"CommandV1","origId":1285,"guid":"42ff1a26-0d12-42f3-8498-718df27280c8","subtype":"command","commandType":"auto","position":3.99993896484375,"command":"# Load spotify user data\nspotify_triplets = sc.textFile(\"/mnt/S3/processed_data/josh_ratings.txt,/mnt/S3/processed_data/oamar_ratings.txt\")\n\nspotify_ratings = spotify_triplets.map(lambda l: l.split(','))\\\n    .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n\n# Sanity check\nprint spotify_ratings.collect()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">[Rating(user=2000000, product=59549, rating=1.0), Rating(user=2000000, product=75801, rating=1.0), Rating(user=2000000, product=112203, rating=1.0), Rating(user=2000000, product=115175, rating=1.0), Rating(user=2000000, product=118577, rating=1.0), Rating(user=2000000, product=121429, rating=1.0), Rating(user=2000000, product=207117, rating=1.0), Rating(user=2000000, product=209717, rating=1.0), Rating(user=2000000, product=327601, rating=1.0), Rating(user=2000000, product=343663, rating=1.0), Rating(user=2000000, product=352389, rating=1.0), Rating(user=2000000, product=352533, rating=1.0), Rating(user=2000000, product=16341, rating=1.0), Rating(user=2000000, product=48728, rating=1.0), Rating(user=2000000, product=980, rating=1.0), Rating(user=2000000, product=8680, rating=1.0), Rating(user=2000000, product=100374, rating=1.0), Rating(user=2000000, product=108841, rating=1.0), Rating(user=2000000, product=49607, rating=1.0), Rating(user=2000000, product=54980, rating=1.0), Rating(user=2000000, product=78565, rating=1.0), Rating(user=2000000, product=79593, rating=1.0), Rating(user=2000000, product=152967, rating=1.0), Rating(user=2000000, product=161822, rating=1.0), Rating(user=2000000, product=125695, rating=1.0), Rating(user=2000000, product=140075, rating=1.0), Rating(user=2000000, product=283043, rating=1.0), Rating(user=2000000, product=295419, rating=1.0), Rating(user=2000000, product=109012, rating=1.0), Rating(user=2000000, product=112051, rating=1.0), Rating(user=2000000, product=259418, rating=1.0), Rating(user=2000000, product=262027, rating=1.0), Rating(user=2000000, product=172679, rating=1.0), Rating(user=2000000, product=197623, rating=1.0), Rating(user=2000000, product=320682, rating=1.0), Rating(user=2000000, product=325522, rating=1.0), Rating(user=3000000, product=70863, rating=1.0), Rating(user=3000000, product=101172, rating=1.0), Rating(user=3000000, product=130534, rating=1.0), Rating(user=3000000, product=145490, rating=1.0), Rating(user=3000000, product=214572, rating=1.0), Rating(user=3000000, product=237465, rating=1.0), Rating(user=3000000, product=345044, rating=1.0), Rating(user=3000000, product=358614, rating=1.0), Rating(user=3000000, product=45282, rating=1.0), Rating(user=3000000, product=45486, rating=1.0), Rating(user=3000000, product=4478, rating=1.0), Rating(user=3000000, product=125755, rating=1.0), Rating(user=3000000, product=128154, rating=1.0), Rating(user=3000000, product=183983, rating=1.0), Rating(user=3000000, product=185591, rating=1.0), Rating(user=3000000, product=116310, rating=1.0), Rating(user=3000000, product=251822, rating=1.0), Rating(user=3000000, product=295464, rating=1.0), Rating(user=3000000, product=46737, rating=1.0), Rating(user=3000000, product=129654, rating=1.0), Rating(user=3000000, product=146503, rating=1.0), Rating(user=3000000, product=198515, rating=1.0), Rating(user=3000000, product=239209, rating=1.0), Rating(user=3000000, product=299047, rating=1.0)]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"py4j.Py4JException: Method textFile([class java.lang.String, class java.lang.String]) does not exist","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-3-549fa6a2b58d&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      2</span> spotify_triplets = sc.textFile(&quot;/mnt/S3/processed_data/josh_ratings.txt&quot;,\n<span class=\"ansigreen\">      3</span>                               <span class=\"ansiblue\">&quot;/mnt/S3/processed_data/oamar_ratings.txt&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\">                               &quot;/mnt/S3/processed_data/james_ratings.txt&quot;)\n</span><span class=\"ansigreen\">      5</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span> spotify_ratings <span class=\"ansiyellow\">=</span> spotify_triplets<span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> l<span class=\"ansiyellow\">:</span> l<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;,&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span>    <span class=\"ansiyellow\">.</span>map<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> l<span class=\"ansiyellow\">:</span> Rating<span class=\"ansiyellow\">(</span>int<span class=\"ansiyellow\">(</span>l<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> int<span class=\"ansiyellow\">(</span>l<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> float<span class=\"ansiyellow\">(</span>l<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">2</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/context.pyc</span> in <span class=\"ansicyan\">textFile</span><span class=\"ansiblue\">(self, name, minPartitions, use_unicode)</span>\n<span class=\"ansigreen\">    474</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    475</span>         minPartitions <span class=\"ansiyellow\">=</span> minPartitions <span class=\"ansigreen\">or</span> min<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>defaultParallelism<span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">2</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 476</span><span class=\"ansiyellow\">         return RDD(self._jsc.textFile(name, minPartitions), self,\n</span><span class=\"ansigreen\">    477</span>                    UTF8Deserializer(use_unicode))\n<span class=\"ansigreen\">    478</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1131</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1132</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1133</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1134</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1135</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.pyc</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    321</span>                 raise Py4JError(\n<span class=\"ansigreen\">    322</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 323</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name, value))\n</span><span class=\"ansigreen\">    324</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    325</span>             raise Py4JError(\n\n<span class=\"ansired\">Py4JError</span>: An error occurred while calling o70.textFile. Trace:\npy4j.Py4JException: Method textFile([class java.lang.String, class java.lang.String]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:272)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\n</div>","workflows":[],"startTime":1.482024490277E12,"submitTime":1.48202441692E12,"finishTime":1.482024490849E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"975a1de3-99f7-48a9-8fac-0b9b0160e7e0"},{"version":"CommandV1","origId":1286,"guid":"215a9fb1-9613-468a-bec3-d58be6449472","subtype":"command","commandType":"auto","position":3.999969482421875,"command":"# Join with full ratings\ncustom_ratings = ratings_full.union(spotify_ratings)\n\n# Retrain model on all data\nmodel = implicit_recommender()\nbest_params = {'rank': 50, \n              'iterations': 5,\n              'alpha': 40.,\n              'lambda_': 1.0\n}\n\nmodel.train_model(custom_ratings, best_params)\n\n# Output the final model\npath_to_models = '/mnt/S3/models'\nfile_name = 'spotify_model'\nmodel.save(os.path.join(path_to_models, file_name))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Saving model to file...\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">ValueError</span>: RDD is empty","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-5-ae9403cc5172&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     10</span> }\n<span class=\"ansigreen\">     11</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 12</span><span class=\"ansiyellow\"> </span>model<span class=\"ansiyellow\">.</span>train_model<span class=\"ansiyellow\">(</span>custom_ratings<span class=\"ansiyellow\">,</span> best_params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     13</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     14</span> <span class=\"ansired\"># Output the final model</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-2-03fd2517dd95&gt;</span> in <span class=\"ansicyan\">train_model</span><span class=\"ansiblue\">(self, data, params)</span>\n<span class=\"ansigreen\">    165</span>   <span class=\"ansigreen\">def</span> train_model<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> data<span class=\"ansiyellow\">,</span> params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    166</span>     <span class=\"ansiblue\">&quot;&quot;&quot;Train on the data&quot;&quot;&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 167</span><span class=\"ansiyellow\">     </span>self<span class=\"ansiyellow\">.</span>model <span class=\"ansiyellow\">=</span> ALS<span class=\"ansiyellow\">.</span>trainImplicit<span class=\"ansiyellow\">(</span>data<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>params<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    168</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    169</span> <span class=\"ansigreen\">class</span> popularity_recommender<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/mllib/recommendation.pyc</span> in <span class=\"ansicyan\">trainImplicit</span><span class=\"ansiblue\">(cls, ratings, rank, iterations, lambda_, blocks, alpha, nonnegative, seed)</span>\n<span class=\"ansigreen\">    311</span>           <span class=\"ansiyellow\">(</span>default<span class=\"ansiyellow\">:</span> None<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    312</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 313</span><span class=\"ansiyellow\">         model = callMLlibFunc(&quot;trainImplicitALSModel&quot;, cls._prepare(ratings), rank,\n</span><span class=\"ansigreen\">    314</span>                               iterations, lambda_, blocks, alpha, nonnegative, seed)\n<span class=\"ansigreen\">    315</span>         <span class=\"ansigreen\">return</span> MatrixFactorizationModel<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/mllib/recommendation.pyc</span> in <span class=\"ansicyan\">_prepare</span><span class=\"ansiblue\">(cls, ratings)</span>\n<span class=\"ansigreen\">    227</span>             raise TypeError(&quot;Ratings should be represented by either an RDD or a DataFrame, &quot;\n<span class=\"ansigreen\">    228</span>                             &quot;but got %s.&quot; % type(ratings))\n<span class=\"ansigreen\">--&gt; 229</span><span class=\"ansiyellow\">         </span>first <span class=\"ansiyellow\">=</span> ratings<span class=\"ansiyellow\">.</span>first<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    230</span>         <span class=\"ansigreen\">if</span> isinstance<span class=\"ansiyellow\">(</span>first<span class=\"ansiyellow\">,</span> Rating<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    231</span>             <span class=\"ansigreen\">pass</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/rdd.pyc</span> in <span class=\"ansicyan\">first</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">   1329</span>         <span class=\"ansigreen\">if</span> rs<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1330</span>             <span class=\"ansigreen\">return</span> rs<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 1331</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">raise</span> ValueError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;RDD is empty&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1332</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1333</span>     <span class=\"ansigreen\">def</span> isEmpty<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ValueError</span>: RDD is empty\n</div>","workflows":[],"startTime":1.482024496125E12,"submitTime":1.482024494742E12,"finishTime":1.482024771954E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"eddee58c-e418-43c0-976a-c25a7669c497"},{"version":"CommandV1","origId":1287,"guid":"55368586-8e1d-4aef-9919-39256b95fb13","subtype":"command","commandType":"auto","position":4.0,"command":"%md # Get User Recommendations","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"576ad99a-2a0a-4849-99cc-e7fc677052a8"},{"version":"CommandV1","origId":1288,"guid":"62191a86-55e1-4c67-91dd-2415f210a0fc","subtype":"command","commandType":"auto","position":5.0,"command":"import os\n# Get recommendations from a saved model\ndef get_model_recommendations(path_to_model, user_ids, num_recs):\n  \"\"\"Get a list of recommendations for a list of users\"\"\"\n  model = MatrixFactorizationModel.load(sc, path_to_model)\n  recommendations = []\n  for user_id in user_ids:\n    recommendations.append(model.recommendProducts(user_id, num_recs))\n  return recommendations\n\n# Load users from ratings file\nusers = ratings.map(lambda x: x.user).distinct().collect()\n\n# Test getting recommendations\npath_to_model = '/mnt/S3/models/good_model'\n\nprint get_model_recommendations(path_to_model, random.choice(users, 2), 10)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">[[Rating(user=244460, product=207426, rating=0.5895467139234798), Rating(user=244460, product=42608, rating=0.45734916449983243), Rating(user=244460, product=263553, rating=0.4481858294404532), Rating(user=244460, product=351767, rating=0.433902266504909), Rating(user=244460, product=49297, rating=0.42310021096988154), Rating(user=244460, product=1559, rating=0.41322847241037775), Rating(user=244460, product=260240, rating=0.40657095254210973), Rating(user=244460, product=375870, rating=0.40085376020705943), Rating(user=244460, product=126840, rating=0.39872035939883954), Rating(user=244460, product=348663, rating=0.3927771743531825)], [Rating(user=644805, product=328222, rating=0.8411121912037225), Rating(user=644805, product=308527, rating=0.8352219567578797), Rating(user=644805, product=332336, rating=0.7976634157804784), Rating(user=644805, product=252032, rating=0.7815422810949573), Rating(user=644805, product=283725, rating=0.7734849063163267), Rating(user=644805, product=263553, rating=0.7151309787561758), Rating(user=644805, product=15018, rating=0.7137975039639144), Rating(user=644805, product=345695, rating=0.7125150245993541), Rating(user=644805, product=51814, rating=0.7009409911423498), Rating(user=644805, product=374994, rating=0.692865724168037)]]\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: global name &apos;sample_user&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-27-09bc2cd52889&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     15</span> path_to_model <span class=\"ansiyellow\">=</span> <span class=\"ansiblue\">&apos;/mnt/S3/models/test_model&apos;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     16</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 17</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">print</span> get_model_recommendations<span class=\"ansiyellow\">(</span>path_to_model<span class=\"ansiyellow\">,</span> random<span class=\"ansiyellow\">.</span>choice<span class=\"ansiyellow\">(</span>users<span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">2</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">10</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;ipython-input-27-09bc2cd52889&gt;</span> in <span class=\"ansicyan\">get_model_recommendations</span><span class=\"ansiblue\">(path_to_model, user_ids, num_recs)</span>\n<span class=\"ansigreen\">      6</span>   recommendations <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      7</span>   <span class=\"ansigreen\">for</span> user_id <span class=\"ansigreen\">in</span> user_ids<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 8</span><span class=\"ansiyellow\">     </span>recommendations<span class=\"ansiyellow\">.</span>append<span class=\"ansiyellow\">(</span>model<span class=\"ansiyellow\">.</span>recommendProducts<span class=\"ansiyellow\">(</span>sample_user<span class=\"ansiyellow\">,</span> num_recs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      9</span>   <span class=\"ansigreen\">return</span> recommendations<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     10</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: global name &apos;sample_user&apos; is not defined\n</div>","workflows":[],"startTime":1.481906272605E12,"submitTime":1.481906271268E12,"finishTime":1.481906384677E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f7547511-cbef-416c-84cd-574dd6afd441"}],"dashboards":[],"guid":"2b64385c-da52-40ca-8c6d-b989f0c84e5b","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
<script>var tableOfContentsCell = {"version":"CommandV1","origId":0,"guid":"1856f8d8-10dc-46c6-9738-52a536c4dbb3","subtype":"command","commandType":"auto","position":0.0,"command":"%md [&lsaquo; Back to Table of Contents](index.html)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{}};</script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>